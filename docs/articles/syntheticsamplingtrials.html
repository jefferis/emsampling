<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Synthetic Sampling Trials • emsampling</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Synthetic Sampling Trials">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">emsampling</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">0.1.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/syntheticsamplingtrials.html">Synthetic Sampling Trials</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/jefferis/emsampling">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Synthetic Sampling Trials</h1>
                        <h4 class="author">Gregory Jefferis</h4>
            
            <h4 class="date">2018-08-15</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/jefferis/emsampling/blob/master/vignettes/syntheticsamplingtrials.Rmd"><code>vignettes/syntheticsamplingtrials.Rmd</code></a></small>
      <div class="hidden name"><code>syntheticsamplingtrials.Rmd</code></div>

    </div>

    
    
<div id="introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h2>
<p>We want to think a bit about the process of sampling random partners upstream or downstream of a given neuron. In most cases in FAFB this is prohibitively expensive, so it has rarely been done. However, there are instances, particularly cases where a neuron is locally complete for some arbour. We would like to think about how much we can infer about the distribution of real connection strengths based on knowing the partners for only a random sample of those connections.</p>
<div id="setup" class="section level3">
<h3 class="hasAnchor">
<a href="#setup" class="anchor"></a>Setup</h3>
<p>We first source in some functions that define an object of class <code>samplingcurve</code> that we define to enable some convenience plotting and analysis functions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
<span class="kw">library</span>(emsampling)
<span class="co"># for consistency later ...</span>
<span class="kw">set.seed</span>(<span class="dv">42</span>)</code></pre></div>
</div>
</div>
<div id="toy-examples" class="section level2">
<h2 class="hasAnchor">
<a href="#toy-examples" class="anchor"></a>Toy examples</h2>
<p>Let’s consider some toy examples in order to develop some intuiition for and approaches to this problem.</p>
<div id="uniform-distribution" class="section level3">
<h3 class="hasAnchor">
<a href="#uniform-distribution" class="anchor"></a>Uniform distribution</h3>
<p>The simplest example is a neuron that makes the same number of connections with every partner.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># scuniformp=samplingcurve(sample(1:20, size=200, replace=T))</span>
scuniform=<span class="kw"><a href="../reference/samplingcurve.html">samplingcurve</a></span>(<span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>,<span class="dv">10</span>))
<span class="kw">head</span>(scuniform)
<span class="co">#&gt;   new partner</span>
<span class="co">#&gt; 1   1       1</span>
<span class="co">#&gt; 2   2       2</span>
<span class="co">#&gt; 3   3       3</span>
<span class="co">#&gt; 4   4       4</span>
<span class="co">#&gt; 5   5       5</span>
<span class="co">#&gt; 6   6       6</span></code></pre></div>
<p>Let’s look at the distribution of partners. In this simplest of all cases, it’s uniform.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(scuniform)</code></pre></div>
<p><img src="syntheticsamplingtrials_files/figure-html/unnamed-chunk-3-1.png" width="576"></p>
<p>Now let’s look at what happens as the sampling curve evolves:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(scuniform)</code></pre></div>
<p><img src="syntheticsamplingtrials_files/figure-html/unnamed-chunk-4-1.png" width="576"></p>
<p>Hmm, that’s because the connections are in a non-random order. Let’s randomise. We have a function for that <code>subsample</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">scuniformr=<span class="kw"><a href="../reference/subsample.html">subsample</a></span>(scuniform)
<span class="kw">plot</span>(scuniformr)</code></pre></div>
<p><img src="syntheticsamplingtrials_files/figure-html/unnamed-chunk-5-1.png" width="576"></p>
<p>OK. That looks more reasonable. A brief note about the plot. The red line plots the number of new neurons for each connection tested. There is a horizontal step each time we hit a neuron that we have already seen. The black dashed line is the equality line (y=x), i.e. what we would get if there were only one partner per neuron.</p>
<p>Now, assuming our random sampling is precisely that, we should see different curves for different runs.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(scuniformr, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">lines</span>(scuniform, <span class="dt">rand=</span><span class="dv">20</span>, <span class="dt">col=</span><span class="st">'black'</span>)</code></pre></div>
<p><img src="syntheticsamplingtrials_files/figure-html/unnamed-chunk-6-1.png" width="576"></p>
<p>We can also look at how the proportion of identified targets evolves:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/plot_prop_identified.html">plot_prop_identified</a></span>(scuniformr)</code></pre></div>
<p><img src="syntheticsamplingtrials_files/figure-html/unnamed-chunk-7-1.png" width="576"></p>
<p>In this instance, this is identical to the plot above, just with the axes normalised. Things could be different of course if we set some threshold on which partners (strong?) we wanted to</p>
</div>
<div id="uniform---more-synapses" class="section level3">
<h3 class="hasAnchor">
<a href="#uniform---more-synapses" class="anchor"></a>Uniform - more synapses</h3>
<p>Let’s look at what happens when we have a neuron that makes more synapses but has the same number of partners.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">scuniform2k=<span class="kw"><a href="../reference/samplingcurve.html">samplingcurve</a></span>(<span class="kw">sample</span>(<span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>,<span class="dv">100</span>)))
<span class="kw">plot</span>(scuniform2k)
<span class="kw">lines</span>(scuniform2k, <span class="dt">rand =</span> <span class="dv">100</span>)</code></pre></div>
<p><img src="syntheticsamplingtrials_files/figure-html/unnamed-chunk-8-1.png" width="576"></p>
<p>So we can see that in this situation we need to sample a relatively small fraction of the total number of connections in order to identify all partners. In fact the absolute amount of sampling required is very similar to the case above with 10 connections per partner.</p>
</div>
<div id="how-much-do-we-need-to-sample" class="section level3">
<h3 class="hasAnchor">
<a href="#how-much-do-we-need-to-sample" class="anchor"></a>How much do we need to sample?</h3>
<p>Imagine we want to define a reasonable amount of sampling for the two examples above. For example we might calculate the amount of sampling required to have a 95% chance of identifying 80% of the partners.</p>
<p>We could do this by computing many randomised versions of the sampling curves and then thresholding appropriately.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">required_sample &lt;-<span class="st"> </span><span class="cf">function</span>(x, <span class="dt">required=</span>.<span class="dv">8</span>, <span class="dt">certainty=</span>.<span class="dv">95</span>, <span class="dt">replicates=</span><span class="dv">1000</span>) {
  csx=<span class="cf">function</span>(x) <span class="kw">cumsum</span>(<span class="op">!</span><span class="kw">duplicated</span>(<span class="kw">sample</span>(x)))
  pp=<span class="kw">replicate</span>(replicates, <span class="kw">csx</span>(x<span class="op">$</span>partner))
  
  npartners=<span class="kw">length</span>(<span class="kw">unique</span>(x<span class="op">$</span>partner))
  threshold=npartners<span class="op">*</span>required
  <span class="kw">names</span>(threshold) &lt;-<span class="st"> </span>required
  res=<span class="kw">t</span>(<span class="kw">sapply</span>(threshold, <span class="cf">function</span>(t) <span class="kw">quantile</span>(<span class="kw">colSums</span>(pp<span class="op">&lt;</span>t)<span class="op">+</span><span class="dv">1</span>, <span class="dt">probs =</span> certainty)))
  <span class="kw">attr</span>(res, <span class="st">'x'</span>)=required
  <span class="kw">attr</span>(res, <span class="st">'y'</span>)=certainty
  res
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">required_sample</span>(scuniformr, <span class="dt">certainty =</span> <span class="kw">c</span>(<span class="fl">0.5</span>,<span class="fl">0.9</span>,<span class="fl">0.95</span>,.<span class="dv">975</span>,<span class="fl">0.99</span>))
<span class="co">#&gt;     50% 90% 95% 97.5% 99%</span>
<span class="co">#&gt; 0.8  27  35  37    39  41</span>
<span class="co">#&gt; attr(,"x")</span>
<span class="co">#&gt; [1] 0.8</span>
<span class="co">#&gt; attr(,"y")</span>
<span class="co">#&gt; [1] 0.500 0.900 0.950 0.975 0.990</span>
scuniform2k.rs &lt;-<span class="st"> </span><span class="kw">required_sample</span>(scuniform2k,
                                  <span class="dt">certainty =</span> <span class="kw">c</span>(<span class="fl">0.5</span>,<span class="fl">0.9</span>,<span class="fl">0.95</span>,.<span class="dv">975</span>,<span class="fl">0.99</span>))
scuniform2k.rs
<span class="co">#&gt;     50%  90% 95%  97.5% 99%</span>
<span class="co">#&gt; 0.8  29 38.1  41 44.025  50</span>
<span class="co">#&gt; attr(,"x")</span>
<span class="co">#&gt; [1] 0.8</span>
<span class="co">#&gt; attr(,"y")</span>
<span class="co">#&gt; [1] 0.500 0.900 0.950 0.975 0.990</span></code></pre></div>
<p>So we can read this as saying that we need to sample 41 synapses to have a 95% chance of identifying at least 80% (i.e. 16) of the partners.</p>
<p><code>required_sample</code> is vectorised over both the <code>required</code> fraction of partners identified and the required <code>certainty</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sdist =<span class="st"> </span><span class="kw">required_sample</span>(
  scuniformr,
  <span class="dt">required =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">1</span>, <span class="dt">by =</span> <span class="fl">0.05</span>),
  <span class="dt">certainty =</span> <span class="kw">c</span>(<span class="fl">0.01</span>, .<span class="dv">025</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="fl">0.9</span>, <span class="fl">0.95</span>, .<span class="dv">975</span>, <span class="fl">0.99</span>),
  <span class="dt">replicates =</span> <span class="fl">10e3</span>
  )
knitr<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/knitr/topics/kable">kable</a></span>(sdist)</code></pre></div>
<table class="table">
<thead><tr class="header">
<th></th>
<th align="right">1%</th>
<th align="right">2.5%</th>
<th align="right">5%</th>
<th align="right">10%</th>
<th align="right">50%</th>
<th align="right">90%</th>
<th align="right">95%</th>
<th align="right">97.5%</th>
<th align="right">99%</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>0</td>
<td align="right">1.00</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1.00</td>
</tr>
<tr class="even">
<td>0.05</td>
<td align="right">1.00</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1.00</td>
</tr>
<tr class="odd">
<td>0.1</td>
<td align="right">2.00</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">3.00</td>
</tr>
<tr class="even">
<td>0.15</td>
<td align="right">4.00</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">6</td>
<td align="right">6.00</td>
</tr>
<tr class="odd">
<td>0.2</td>
<td align="right">4.00</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">6</td>
<td align="right">6.00</td>
</tr>
<tr class="even">
<td>0.25</td>
<td align="right">5.00</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">7</td>
<td align="right">7</td>
<td align="right">7</td>
<td align="right">8.00</td>
</tr>
<tr class="odd">
<td>0.3</td>
<td align="right">7.00</td>
<td align="right">7</td>
<td align="right">7</td>
<td align="right">7</td>
<td align="right">8</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">11</td>
<td align="right">12.00</td>
</tr>
<tr class="even">
<td>0.35</td>
<td align="right">8.00</td>
<td align="right">8</td>
<td align="right">8</td>
<td align="right">8</td>
<td align="right">9</td>
<td align="right">12</td>
<td align="right">12</td>
<td align="right">13</td>
<td align="right">14.00</td>
</tr>
<tr class="odd">
<td>0.4</td>
<td align="right">8.00</td>
<td align="right">8</td>
<td align="right">8</td>
<td align="right">8</td>
<td align="right">9</td>
<td align="right">12</td>
<td align="right">12</td>
<td align="right">13</td>
<td align="right">14.00</td>
</tr>
<tr class="even">
<td>0.45</td>
<td align="right">9.00</td>
<td align="right">9</td>
<td align="right">9</td>
<td align="right">9</td>
<td align="right">11</td>
<td align="right">14</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">16.00</td>
</tr>
<tr class="odd">
<td>0.5</td>
<td align="right">10.00</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">11</td>
<td align="right">13</td>
<td align="right">16</td>
<td align="right">17</td>
<td align="right">18</td>
<td align="right">19.00</td>
</tr>
<tr class="even">
<td>0.55</td>
<td align="right">11.00</td>
<td align="right">11</td>
<td align="right">12</td>
<td align="right">12</td>
<td align="right">15</td>
<td align="right">18</td>
<td align="right">19</td>
<td align="right">20</td>
<td align="right">22.00</td>
</tr>
<tr class="odd">
<td>0.6</td>
<td align="right">14.00</td>
<td align="right">14</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">19</td>
<td align="right">23</td>
<td align="right">25</td>
<td align="right">26</td>
<td align="right">28.00</td>
</tr>
<tr class="even">
<td>0.65</td>
<td align="right">14.00</td>
<td align="right">14</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">19</td>
<td align="right">23</td>
<td align="right">25</td>
<td align="right">26</td>
<td align="right">28.00</td>
</tr>
<tr class="odd">
<td>0.7</td>
<td align="right">17.00</td>
<td align="right">18</td>
<td align="right">19</td>
<td align="right">20</td>
<td align="right">24</td>
<td align="right">30</td>
<td align="right">32</td>
<td align="right">35</td>
<td align="right">37.00</td>
</tr>
<tr class="even">
<td>0.75</td>
<td align="right">17.00</td>
<td align="right">18</td>
<td align="right">19</td>
<td align="right">20</td>
<td align="right">24</td>
<td align="right">30</td>
<td align="right">32</td>
<td align="right">35</td>
<td align="right">37.00</td>
</tr>
<tr class="odd">
<td>0.8</td>
<td align="right">19.00</td>
<td align="right">20</td>
<td align="right">21</td>
<td align="right">22</td>
<td align="right">28</td>
<td align="right">35</td>
<td align="right">37</td>
<td align="right">40</td>
<td align="right">42.00</td>
</tr>
<tr class="even">
<td>0.85</td>
<td align="right">21.00</td>
<td align="right">22</td>
<td align="right">24</td>
<td align="right">25</td>
<td align="right">32</td>
<td align="right">41</td>
<td align="right">44</td>
<td align="right">47</td>
<td align="right">51.00</td>
</tr>
<tr class="odd">
<td>0.9</td>
<td align="right">24.00</td>
<td align="right">26</td>
<td align="right">27</td>
<td align="right">29</td>
<td align="right">37</td>
<td align="right">48</td>
<td align="right">52</td>
<td align="right">56</td>
<td align="right">60.00</td>
</tr>
<tr class="even">
<td>0.95</td>
<td align="right">28.00</td>
<td align="right">30</td>
<td align="right">32</td>
<td align="right">34</td>
<td align="right">44</td>
<td align="right">59</td>
<td align="right">64</td>
<td align="right">69</td>
<td align="right">75.00</td>
</tr>
<tr class="odd">
<td>1</td>
<td align="right">33.99</td>
<td align="right">36</td>
<td align="right">39</td>
<td align="right">42</td>
<td align="right">58</td>
<td align="right">81</td>
<td align="right">89</td>
<td align="right">96</td>
<td align="right">105.01</td>
</tr>
</tbody>
</table>
<p>Here the columns represent the quantiles (i.e. certainty) and the rows are the fraction of connections to be found.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(viridis)
<span class="co">#&gt; Loading required package: viridisLite</span>
<span class="kw">filled.contour</span>(sdist, 
               <span class="dt">color.palette =</span> viridis,
               <span class="dt">x =</span> <span class="kw">attr</span>(sdist,<span class="st">'x'</span>),
               <span class="dt">y =</span> <span class="kw">attr</span>(sdist,<span class="st">'y'</span>),
               <span class="dt">xlab=</span><span class="st">'required'</span>,
               <span class="dt">ylab=</span><span class="st">'certainty'</span>,
               <span class="dt">key.title =</span> <span class="kw">title</span>(<span class="dt">main=</span><span class="st">'Samples'</span>)
               )</code></pre></div>
<p><img src="syntheticsamplingtrials_files/figure-html/unnamed-chunk-12-1.png" width="576"></p>
<p>We could repeat this plot normalising the number of samples</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sdist =<span class="st"> </span><span class="kw">required_sample</span>(
  scuniformr,
  <span class="dt">required =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">1</span>, <span class="dt">by =</span> <span class="fl">0.05</span>),
  <span class="dt">certainty =</span> <span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.9</span>, <span class="fl">0.95</span>, .<span class="dv">975</span>, <span class="fl">0.99</span>),
  <span class="dt">replicates =</span> <span class="fl">10e3</span>
  )
<span class="kw">filled.contour</span>(sdist<span class="op">/</span><span class="dv">200</span>, 
               <span class="dt">color.palette =</span> viridis,
               <span class="dt">x =</span> <span class="kw">attr</span>(sdist,<span class="st">'x'</span>),
               <span class="dt">y =</span> <span class="kw">attr</span>(sdist,<span class="st">'y'</span>),
               <span class="dt">xlab=</span><span class="st">'required'</span>,
               <span class="dt">ylab=</span><span class="st">'certainty'</span>,
               <span class="dt">key.title =</span> <span class="kw">title</span>(<span class="dt">main=</span><span class="st">'Frac Sampled'</span>, <span class="dt">cex.main =</span> .<span class="dv">7</span>)
               )</code></pre></div>
<p><img src="syntheticsamplingtrials_files/figure-html/unnamed-chunk-13-1.png" width="576"></p>
</div>
<div id="distribution" class="section level3">
<h3 class="hasAnchor">
<a href="#distribution" class="anchor"></a>Distribution</h3>
<p>The statistical distribution that describes the sampling processes above is the <a href="https://en.wikipedia.org/wiki/Hypergeometric_distribution#Multivariate_hypergeometric_distribution">multivariate hypergeometric distribution</a>. The <code><a href="http://www.rdocumentation.org/packages/extraDistr/topics/MultiHypergeometric">extraDistr::rmvhyper</a></code> function provides an alternative way of generating random variables — however it is less efficient for our purposes of generating a complete sampling sequence from k=1:N connections rather than just a given value of k.</p>
<p>This distribution is classically described as sampling <em>without replacement</em> from an urn containing balls of different colours. In our problem, the colours represent each partner neuron. We can sample <code>k</code> balls of the <code>N</code> total, where there are <code>m</code> colours and each colour appears <code>n_i</code> times (<code>i=1:m</code>).</p>
</div>
</div>
<div id="inference" class="section level2">
<h2 class="hasAnchor">
<a href="#inference" class="anchor"></a>Inference</h2>
<p>In the sections above, we defined a known distribution of partners. However, we will normally not know this when we are carrying out a sampling procedure — if we did, we would not need to worry about sampling.</p>
<p>The more interesting situation for us is the one in which we have partial sampling information in front of us, but we do not know the distribution of the number of balls. While we will normally know the total number of connections, we will not know the number of partners or their distribution. A complete description of the full multivariate hypergeometric parameter set will probably be beyond us, because there would be m parameters (numbers of each colour) to estimate. To see why, consider a (small) real neuron which has 200 connections, with 50% of the partners making 1 or 2 connections, but these weak partners might only contribute 10% of the connections.</p>
<p>It will therefore be more plausible to infer some kind of summary of the distribution of partners. This could be the number of <em>strong</em> partners by some definition or perhaps a histogram that divides connection strengths into coarse groups. Finally it could be hyperparameters that describe the distribution from which the multivariate hypergeometric parameters <code>n_i</code> are drawn. This might for example be a skewed distribution, which could be characterised by e.g. its first 3 or 4 moments. It may well be that the distribution of connection strength can be described by some relatively well known distribution like the exponential distribution, in which case 1 or 2 parameters might suffice.</p>
<div id="toy-inference" class="section level3">
<h3 class="hasAnchor">
<a href="#toy-inference" class="anchor"></a>Toy inference</h3>
<p>To get a handle on the problem, we will start by considering the same uniform distribution of partners used above. So the problem resolves to defining the number of partner neurons (m).</p>
<p>Let’s imagine that we have in front of us a 25% sample of the first neuron that we used.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">scuniform.<span class="dv">25</span>=<span class="kw"><a href="../reference/subsample.html">subsample</a></span>(scuniformr, <span class="dt">fraction =</span> <span class="fl">0.25</span>)
<span class="kw">plot</span>(scuniform.<span class="dv">25</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">20</span>), <span class="dt">lwd=</span><span class="dv">3</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">20</span>, <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">'grey'</span>)</code></pre></div>
<p><img src="syntheticsamplingtrials_files/figure-html/unnamed-chunk-14-1.png" width="576"></p>
<p>Now in this case we found 18/20 partners, but of course we might have hit a different number by chance.</p>
<p>We could try to identify the most likely value for <code>m</code> by simulating a 25% sample for many values of m and then choosing the one most likely to generate the observed sampling curve. Now we know that <code>m</code> must be greater than</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mvh_uniform_mle &lt;-<span class="st"> </span><span class="cf">function</span>(x, <span class="dt">ni=</span><span class="ot">NULL</span>, <span class="dt">N=</span><span class="kw">attr</span>(x, <span class="st">'N'</span>), ...) {
  <span class="kw">stopifnot</span>(<span class="kw">inherits</span>(x,<span class="st">'samplingcurve'</span>))
  <span class="kw">stopifnot</span>(<span class="kw">isTRUE</span>(N<span class="op">&gt;</span><span class="dv">1</span>))
  observed_m=<span class="kw">length</span>(<span class="kw">unique</span>(x<span class="op">$</span>partner))
  max_m=N <span class="co"># hopefully this is massive overestimate</span>
  <span class="co"># would be great if we could adaptively reduce max_m when we have gone over</span>
  <span class="co"># the hump</span>
  <span class="cf">if</span>(<span class="kw">is.null</span>(ni))
    ni=<span class="kw">seq.int</span>(observed_m, max_m)
  <span class="cf">else</span> {
    <span class="co"># check we have a sensible range</span>
    <span class="cf">if</span>(ni[<span class="dv">1</span>]<span class="op">&lt;</span>observed_m) {
      <span class="kw">warning</span>(<span class="st">"minimum ni &lt; observed_m"</span>)
    }
    <span class="kw">stopifnot</span>(ni[<span class="kw">length</span>(ni)]<span class="op">&lt;</span>max_m)
  }
  k=<span class="kw">nrow</span>(x)
  
  <span class="co"># calculate number of observations matching observed value for each n_i</span>
  nobs=<span class="kw">sapply</span>(ni, 
              <span class="cf">function</span>(m) <span class="kw">sum</span>(<span class="kw">rowSums</span>(
                <span class="kw"><a href="../reference/urmvhyper.html">urmvhyper</a></span>(<span class="dt">N=</span>N, <span class="dt">m=</span>m, <span class="dt">k=</span>k, ...)<span class="op">&gt;</span><span class="dv">0</span>)<span class="op">==</span>observed_m)
              )
  <span class="kw">names</span>(nobs)=ni
  nobs
}</code></pre></div>
<p>Now, let’s use those functions:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mvh_uniform_mle</span>(scuniform.<span class="dv">25</span>, <span class="dt">ni=</span><span class="dv">19</span><span class="op">:</span><span class="dv">24</span>)
<span class="co">#&gt;   19   20   21   22   23   24 </span>
<span class="co">#&gt; 4164 2212  942  302  117   41</span>
<span class="kw">mvh_uniform_mle</span>(<span class="kw"><a href="../reference/subsample.html">subsample</a></span>(scuniform2k, <span class="dt">fraction =</span> .<span class="dv">05</span>), <span class="dt">ni=</span><span class="dv">19</span><span class="op">:</span><span class="dv">24</span>)
<span class="co">#&gt;   19   20   21   22   23   24 </span>
<span class="co">#&gt; 9295  974   68    4    1    0</span></code></pre></div>
<p>Now, in both cases we see that m=20 partners is our maxmimum likelihood estimate.</p>
</div>
<div id="using-the-sampling-curve" class="section level3">
<h3 class="hasAnchor">
<a href="#using-the-sampling-curve" class="anchor"></a>Using the sampling curve</h3>
<p>The preceding section developed a maximum likelihood approach to estimating the number of partners in our toy example. This is all very well, but it actually uses almost none of the information inherent in the sampling curve. In particular it uses only the final number of partners observed rather than the distribution of randomly observed connection strengths.</p>
<p>We could think about the features of this distribution being encapsulated in the staircase nature of the sampling curve. Here is an example of such a curve (red line) for a 25% sample of our toy neuron’s connections; additional 25% samples are plotted in grey.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(scuniform.<span class="dv">25</span>, <span class="dt">lwd=</span><span class="dv">3</span>)
<span class="co"># add lines resampling from the full partner data</span>
<span class="kw">lines</span>(scuniform, <span class="dt">rand =</span> <span class="dv">20</span>)</code></pre></div>
<p><img src="syntheticsamplingtrials_files/figure-html/unnamed-chunk-17-1.png" width="576"></p>
<p>The red line looks like it belongs within the family of grey curves. But what we can we say about the general form of these sampling curves? First of all, the order of connections selected in each sampling curve is irrelevant. Therefore any permutation of the selected connections is equally valid representation of that particular sample.</p>
<p>Let’s look at a plot with a re-ordering of that 25% sample. We can generalise the step function to a mean curve. The <code><a href="../reference/samplingcurve.html">lines.samplingcurve()</a></code> method can do that for us.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(scuniform.<span class="dv">25</span>)
<span class="co"># plot 20 random re-ordering (grey dotted lines)</span>
<span class="kw">lines</span>(scuniform.<span class="dv">25</span>, <span class="dt">rand=</span><span class="dv">20</span>, <span class="dt">col=</span><span class="st">'grey'</span>)
<span class="co"># plot the mean of 2000 reorderings</span>
<span class="kw">lines</span>(scuniform.<span class="dv">25</span>, <span class="dt">rand=</span><span class="dv">2000</span>, <span class="dt">mean=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">'blue'</span>)</code></pre></div>
<p><img src="syntheticsamplingtrials_files/figure-html/unnamed-chunk-18-1.png" width="576"></p>
<p>Now it’s important to realise that permuting one set of sampled connections is not the same as drawing the same number of connections from the total number available. You can see this in the following plot, which compares two different random draws (green vs grey) vs blue the smooth plot derived from permuting all of the connections.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(scuniform.<span class="dv">25</span>)
<span class="kw">lines</span>(scuniform.<span class="dv">25</span>, <span class="dt">rand=</span><span class="dv">2000</span>, <span class="dt">mean=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">'grey'</span>)
<span class="co"># compare with another random 25% draw</span>
scuniform.25v2=<span class="kw"><a href="../reference/subsample.html">subsample</a></span>(scuniformr, <span class="dt">fraction=</span><span class="fl">0.25</span>)
<span class="kw">lines</span>(scuniform.25v2, <span class="dt">rand=</span><span class="dv">2000</span>, <span class="dt">mean=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">'green'</span>)
<span class="kw">lines</span>(scuniformr, <span class="dt">rand=</span><span class="dv">2000</span>, <span class="dt">mean=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">'blue'</span>)</code></pre></div>
<p><img src="syntheticsamplingtrials_files/figure-html/unnamed-chunk-19-1.png" width="576"></p>
</div>
<div id="histogram-representation" class="section level3">
<h3 class="hasAnchor">
<a href="#histogram-representation" class="anchor"></a>Histogram representation</h3>
<p>Given the fact that in a random sampling paradigm, the sampling order should not have any meaning, it seems reasonable to think that all the informationg inherent in the sample is actually contained only in the number of hits for each partner. In a real life situation, it would probably make sense to check that the observed sample is consistent with a random sample (I think you could compare with permuted versions and see whether it falls within a reasonable envelope).</p>
<p>There is a method <code><a href="../reference/samplingcurve.html">hist.samplingcurve()</a></code> that produces a nice order plot of the connection numbers. Naturally if you try this on a random sample, it will not be uniform. For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(scuniform.<span class="dv">25</span>)</code></pre></div>
<p><img src="syntheticsamplingtrials_files/figure-html/unnamed-chunk-20-1.png" width="576"></p>
<p>In fact, since for these purposes we do not distinguish between different individual partners, the distribution of connection strengths is a useful summary, and equally informative.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">table</span>(<span class="kw">table</span>(scuniform.<span class="dv">25</span><span class="op">$</span>partner)), <span class="dt">ylab=</span><span class="st">'Number of Partner Neurons'</span>,
     <span class="dt">xlab=</span><span class="st">'No of Connections'</span>)</code></pre></div>
<p><img src="syntheticsamplingtrials_files/figure-html/unnamed-chunk-21-1.png" width="576"></p>
</div>
<div id="partner-strength-distribution" class="section level3">
<h3 class="hasAnchor">
<a href="#partner-strength-distribution" class="anchor"></a>Partner strength distribution</h3>
<p>So can we use these data to carry out the same kind of maximum likelihood fit? And can we ask if they are consistent with a uniform distribution?</p>
<p>The second question feels a little easier. We could characterise the deviation of the distribution from some mean/expected value and compare the statistic with a null distribution derived from the proposed distribution. Ah, but we do actually need to know the number of partner neurons to calculate the expected distribution!</p>
<p>Let’s make a start by computing an expected distribution for a given number of partners for a given sampling fraction</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">e_partner_strength_urmvhyper &lt;-<span class="st"> </span><span class="cf">function</span>(m, <span class="dt">nbins=</span>m, ..., <span class="dt">normalise=</span><span class="ot">TRUE</span>) {
  <span class="co"># nb nbins will be an overestimate ...</span>
  rr=<span class="kw">apply</span>(<span class="kw"><a href="../reference/urmvhyper.html">urmvhyper</a></span>(<span class="dt">m=</span>m, ...), <span class="dv">1</span>, tabulate, nbins)
  <span class="cf">if</span>(normalise)
    rr =<span class="st"> </span><span class="kw">scale</span>(rr, <span class="dt">center =</span> F, <span class="dt">scale =</span> <span class="kw">colSums</span>(rr))
  <span class="kw">rowMeans</span>(rr)
}

<span class="co"># what we would expect for a 25% sample</span>
expected_<span class="dv">25</span>=<span class="kw">e_partner_strength_urmvhyper</span>(<span class="dt">m=</span><span class="dv">20</span>, <span class="dt">N=</span><span class="dv">200</span>, <span class="dt">k=</span><span class="dv">50</span>)

tt=<span class="kw">tabulate</span>(<span class="kw">table</span>(scuniform.<span class="dv">25</span><span class="op">$</span>partner), <span class="dt">nbins =</span> <span class="dv">20</span>)
tt_norm=tt<span class="op">/</span><span class="kw">sum</span>(tt)
<span class="kw">plot</span>(expected_<span class="dv">25</span>, <span class="dt">type=</span><span class="st">'l'</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="kw">max</span>(tt_norm)), <span class="dt">col=</span><span class="st">'red'</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">lines</span>(tt_norm)</code></pre></div>
<p><img src="syntheticsamplingtrials_files/figure-html/unnamed-chunk-22-1.png" width="576"></p>
<p>I assume that there’s an analytic solution for the expected distribution, but don’t know what it is. One can then compare with that observed sample. Presumably you could use a chi2 goodness of fit or a perhaps the KL divergence to measure the difference.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#introduction">Introduction</a></li>
      <li><a href="#toy-examples">Toy examples</a></li>
      <li><a href="#inference">Inference</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Gregory Jefferis.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>
